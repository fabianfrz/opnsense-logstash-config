filter {
  if ![@metadata][skip_ls_filter] {
    mutate {
      remove_field => [
        # Ensure unneeded field is absent. The field is added by input plugins
        # or when cloning an event thus the field removal is done later in the
        # pipeline.
        # See also: https://github.com/elastic/logstash/issues/3866
        "@version"
      ]
    }

    # ## https://www.elastic.co/blog/logstash-lessons-handling-duplicates
    # ## SHA2 is chosen because it is considered cryptographically secure (other than SHA1 which is broken).
    # ## SHA512 is chosen over SHA256 because SHA512 is considered faster on modern CPUs.
    # fingerprint {
    #   ## jq '. | keys | .[]' output/*.json | grep --invert-match --perl-regexp '^"(?:#)' | sort --unique | paste -s -d ","
    #   source => [
    #     "msg",
    #     "@timestamp",
    #     "host",
    #     "severity",
    #   ]
    #   ## Set to false so that adding or removing of fields in "source" does not change the HMAC.
    #   ## It should only exist if the field is actually present in the document.
    #   concatenate_sources => false
    #   target => "[@metadata][_id]"
    #   method => "SHA512"
    #   ## The key of the HMAC can be used to proof the authenticity of the
    #   ## source fields as a side effect.
    #   ## Note that HMAC is an authentication code and not an "encryption".
    #   key => "XXX"
    #   base64encode => true
    # }

    # ## Truncate is done because authentication code is merely a side effect but
    # ## can still be used, only with limited size.
    # truncate {
    #   fields => ["[@metadata][_id]"]
    #   length_bytes => 23
    # }

  }
}
